{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-30T09:23:12.858957Z",
     "start_time": "2025-11-30T09:23:12.856282Z"
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torchvision.transforms"
   ],
   "outputs": [],
   "execution_count": 102
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T09:23:12.999594Z",
     "start_time": "2025-11-30T09:23:12.870150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "\n",
    "DATA_DIR = 'data/cifar-10-batches-py'\n",
    "LABEL_FILE = 'batches.meta'\n",
    "TEST_DATA = 'test_batch'\n",
    "\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        data = pickle.load(fo, encoding='bytes')\n",
    "    return data\n",
    "\n",
    "def load_cifar_batches(data_dir):\n",
    "    \"\"\"Load all training batches and the metadata.\"\"\"\n",
    "\n",
    "    all_data = []\n",
    "    all_labels = []\n",
    "\n",
    "    for i in range(1, 6):\n",
    "        file_path = os.path.join(data_dir, f'data_batch_{i}')\n",
    "        batch_dict = unpickle(file_path)\n",
    "\n",
    "        # Keys are stored as bytes, so we need to decode them\n",
    "        data = batch_dict[b'data']\n",
    "        labels = batch_dict[b'labels']\n",
    "\n",
    "        all_data.append(data)\n",
    "        all_labels.extend(labels)\n",
    "\n",
    "    X_train = np.concatenate(all_data)\n",
    "    y_train = np.array(all_labels)\n",
    "\n",
    "    # Load Test Data\n",
    "    test_file_path = os.path.join(data_dir, TEST_DATA)\n",
    "    test_dict = unpickle(test_file_path)\n",
    "    X_test = test_dict[b'data']\n",
    "    y_test = np.array(test_dict[b'labels'])\n",
    "\n",
    "    # Load Metadata (Class Names)\n",
    "    meta_file_path = os.path.join(data_dir, LABEL_FILE)\n",
    "    meta_dict = unpickle(meta_file_path)\n",
    "    class_names = [name.decode('utf-8') for name in meta_dict[b'label_names']]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, class_names\n",
    "\n",
    "X_train, y_train, X_test, y_test, class_names = load_cifar_batches(DATA_DIR)"
   ],
   "id": "2369bfb4a91bb236",
   "outputs": [],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T09:23:13.007841Z",
     "start_time": "2025-11-30T09:23:13.004796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Dataset X_train shape: {X_train.shape}\")\n",
    "print(f\"Dataset y_train shape: {y_train.shape}\")\n",
    "print(f\"Test dataset X_test shape: {X_test.shape}\")\n",
    "print(f\"Test dataset y_test shape: {y_test.shape}\")\n",
    "print(f\"Classes number: {len(class_names)}\")"
   ],
   "id": "772c2ed9908bc8c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset X_train shape: (50000, 3072)\n",
      "Dataset y_train shape: (50000,)\n",
      "Test dataset X_test shape: (10000, 3072)\n",
      "Test dataset y_test shape: (10000,)\n",
      "Classes number: 10\n"
     ]
    }
   ],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T09:23:13.021724Z",
     "start_time": "2025-11-30T09:23:13.018581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Total training samples: {X_train.shape[0]}\")\n",
    "print(f\"Shape of one image: {X_train.shape[1]} (32 * 32 * 3)\")\n",
    "print(f\"Class names: {class_names}\")\n",
    "\n",
    "# Example: Reshape a single image to see its dimensions\n",
    "# The 3072 pixels are stored as (R-channel, G-channel, B-channel)\n",
    "# Each channel has 1024 pixels (32x32)\n",
    "example_image = X_train[0].reshape(3, 32, 32).transpose(1, 2, 0) # Transpose for (H, W, C)\n",
    "print(f\"Shape of first image after reshaping: {example_image.shape}\")\n",
    "print(f\"Label of first image: {class_names[y_train[0].item()]}\")"
   ],
   "id": "1baff200af3db97d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 50000\n",
      "Shape of one image: 3072 (32 * 32 * 3)\n",
      "Class names: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "Shape of first image after reshaping: (32, 32, 3)\n",
      "Label of first image: frog\n"
     ]
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T09:23:13.040322Z",
     "start_time": "2025-11-30T09:23:13.036017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "class Cifar10RawDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_data = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Reshape the flattened image: (3072,) -> (3, 32, 32)\n",
    "        # and convert to a NumPy array for compatibility with torchvision.transforms\n",
    "        image = image_data.reshape(3, 32, 32).transpose(1, 2, 0)\n",
    "\n",
    "        # Apply the transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ],
   "id": "4e7bcf2324da3385",
   "outputs": [],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T09:23:13.064498Z",
     "start_time": "2025-11-30T09:23:13.061065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# CIFAR-10 standard mean and standard deviation\n",
    "CIFAR_MEAN = [0.4914, 0.4822, 0.4465]\n",
    "CIFAR_STD = [0.2023, 0.1994, 0.2010]\n",
    "\n",
    "# Training Transformations (includes augmentation)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),    # Convert HWC NumPy array to PIL image\n",
    "    transforms.RandomHorizontalFlip(),  # Augmentation\n",
    "    transforms.RandomCrop(32, padding=4),   # Augmentation\n",
    "    transforms.ToTensor(),      # Convert PIL image to Tensor\n",
    "    transforms.Normalize(CIFAR_MEAN, CIFAR_STD) # Scales to [0, 1]\n",
    "])\n",
    "\n",
    "# Testing/Validation Transformation (no augmentation)\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(CIFAR_MEAN, CIFAR_STD)\n",
    "])"
   ],
   "id": "f5cb81ddde6eef86",
   "outputs": [],
   "execution_count": 107
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T09:23:13.074001Z",
     "start_time": "2025-11-30T09:23:13.070854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Transform data in a different approach\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(40),\n",
    "    torchvision.transforms.RandomResizedCrop(32, scale=(0.64, 1.0), ratio=(1.0, 1.0)),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010]),\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010]),\n",
    "])"
   ],
   "id": "ac871a469cbaeb88",
   "outputs": [],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T09:23:13.083788Z",
     "start_time": "2025-11-30T09:23:13.077039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create Datasets\n",
    "train_dataset = Cifar10RawDataset(X_train, y_train, train_transform)\n",
    "test_dataset = Cifar10RawDataset(X_test, y_test, test_transform)\n",
    "\n",
    "# Create DataLoaders\n",
    "BATCH_SIZE = 64\n",
    "NUM_OF_WORKERS = 4\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_OF_WORKERS)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=NUM_OF_WORKERS)"
   ],
   "id": "688115def1cc172",
   "outputs": [],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T09:23:13.090660Z",
     "start_time": "2025-11-30T09:23:13.088222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Number of training batches: {len(train_loader)}\")\n",
    "print(f\"Number of training data points: {len(train_loader.dataset)}\")"
   ],
   "id": "cfc4bd0a9b036e05",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training batches: 782\n",
      "Number of training data points: 50000\n"
     ]
    }
   ],
   "execution_count": 110
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
